# Ollama-chat

Web interface to chat with a locally installed Large Language Model via Ollama. Check out the tutorial from the author here - https://medium.com/@mpalmerlee/building-an-llm-chat-interface-using-ollama-and-vue-5bf4e2fc65fd

Uses:

* [ollama](https://ollama.com/)
* [Vue.js](https://vuejs.org/)
* [Vite](https://vitejs.dev/)
* [PrimeVue](https://primevue.org/)
* [TanStack Query](https://tanstack.com/query/latest)

## Project Setup

```sh
npm install
```

### Compile and Hot-Reload for Development

```sh
npm run dev
```

### Type-Check, Compile and Minify for Production

```sh
npm run build
```

### Lint with [ESLint](https://eslint.org/)

```sh
npm run lint
```
